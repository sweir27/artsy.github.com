<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Continuous Integration | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/continuous-integration/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2014-03-17T18:12:04+00:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[Artsy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Run RSpec Test Suites in Parallel with JenkinsCI Build Flow]]></title>
    <link href="http://artsy.github.io/blog/2012/10/09/how-to-run-rspec-test-suites-in-parallel-with-jenkins-ci-build-flow/"/>
    <updated>2012-10-09T21:21:00+01:00</updated>
    <id>http://artsy.github.io/blog/2012/10/09/how-to-run-rspec-test-suites-in-parallel-with-jenkins-ci-build-flow</id>
    <content type="html"><![CDATA[<p>We now have over 4700 RSpec examples in one of our projects. They are stable, using the techniques described in an <a href="/blog/2012/02/03/reliably-testing-asynchronous-ui-w-slash-rspec-and-capybara/">earlier post</a> and organized in <a href="/blog/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures/">suites</a>. But they now take almost 3 hours to run, which is clearly unacceptable.</p>

<p>To solve this, we have parallelized parts of the process with existing tools, and can turn a build around in just under an hour. This post will dive into our <a href="http://jenkins-ci.org/">Jenkins</a> build flow setup.</p>

<p>To keep things simple, we're going to only build the <code>master</code> branch. When a change is committed on <code>master</code> we're going to push <code>master</code> to a <code>master-ci</code> branch and trigger a distributed build on <code>master-ci</code>. Once all the parts have finished, we'll complete the build by pushing <code>master-ci</code> to <code>master-succeeded</code> and notify the dev team of success or failure.</p>

<p>Here's a diagram of what's going on.</p>

<p><img src="http://artsy.github.io/images/2012-10-09-how-to-run-rspec-test-suites-in-parallel-with-jenkins-ci-build-flow/master-ci.png"></p>

<!-- more -->


<h2>Plugins</h2>

<p>Install the <a href="https://wiki.jenkins-ci.org/display/JENKINS/Build+Flow+Plugin">Build Flow</a> and the <a href="https://wiki.jenkins-ci.org/display/JENKINS/Parameterized+Trigger+Plugin">Parameterized Trigger</a> plugin. Grant <code>Anonymous</code> job read permissions in Jenkins system configuration (see <a href="https://issues.jenkins-ci.org/browse/JENKINS-14027">JENKINS-14027</a>).</p>

<p>Create the following Jenkins jobs.</p>

<h2>master-prequel</h2>

<p>A free-style job that connects to the SCM, in our case Git.</p>

<ul>
<li>Set SCM repository URL to your Git repo, eg. <code>git@github.com:spline/reticulator.git</code></li>
<li>Change the default branch specifier from <code>**</code> to <code>master</code>. We'll be pushing a <code>master-ci</code> branch, which could, in turn, cause more builds if you don't do this.</li>
<li>Add a post-build action to build another project. Trigger the <code>master</code> project if the build succeeds.</li>
</ul>


<h2>master</h2>

<p>This is a build-flow job. We'll describe the individual tasks that the flow invokes further. The flow DSL looks as follows.</p>

<p><code>ruby
build("master-ci-init")
parallel (
 { build("master-ci-task", tasks: "spec:suite:models:ci") },
 { build("master-ci-task", tasks: "spec:suite:api:ci") },
 { build("master-ci-task", tasks: "spec:suite:integration:ci") }
)
build("master-ci-succeeded")
</code></p>

<p>This is a good place to add an e-mail notification post-build action for every unstable build.</p>

<h2>master-ci-init</h2>

<p>A free-style job that creates the <code>master-ci</code> branch from master. It needs to be connected to your SCM and executes the following shell script.</p>

<p>``` bash</p>

<h1>!/bin/bash</h1>

<p>git checkout $GIT_BRANCH
git push origin -f $GIT_BRANCH:$GIT_BRANCH-ci
```</p>

<p>Note that we cannot combine this task with <code>master-prequel</code>, because we have to make sure the branch creation runs once under the entire flow, while <code>master-prequel</code> can be run multiple times, once per check-in. Otherwise the <code>master-ci</code> branch could get updated before a <code>master-ci-task</code> runs from a previous flow execution.</p>

<h2>master-ci-task</h2>

<p>A parameterized build that accepts a <code>tasks</code> parameter that the flow will pass in.</p>

<p>Change the default branch specifier to <code>master-ci</code> and execute the following shell script.</p>

<p>``` bash</p>

<h1>!/bin/bash</h1>

<p>bundle install
bundle exec rake $tasks
```</p>

<p>This example runs <code>rake $tasks</code>, which we define to be various test suites in our flow DSL. Our test suite setup is described in <a href="/blog/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures/">this post</a>. Your mileage may vary.</p>

<h2>master-ci-succeeded</h2>

<p>This is an optional step. We use this free-style job to tag <code>master-ci</code> as <code>master-succeeded</code> with the following shell script.</p>

<p>``` bash</p>

<h1>!/bin/bash</h1>

<p>git checkout $GIT_BRANCH
git push origin -f $GIT_BRANCH:${GIT_BRANCH/%-ci/}-succeeded
```</p>

<p>Our deployment to production will pickup the <code>master-succeeded</code> branch when it's time.</p>

<h2>Improvements?</h2>

<p>I see a few possible improvements here that might require a bit of work.</p>

<ul>
<li>The ability to split an RSpec suite up across an arbitrary number N sub-jobs and M executors would create an optimal parallel split based on the resources available.</li>
<li>Passing the value of <code>GIT_BRANCH</code> and <code>GIT_COMMIT</code> across these jobs would enable building any branch and eliminate the need for <code>master-ci-init</code>.</li>
<li>Build flow could support SCM polling the same way as free-style jobs, avoiding the need for <code>master-prequel</code>. We weren't able to get a stable notification of changes from Github with the Jenkins Github plugin.</li>
</ul>


<p>Please suggest further improvements in the comments below!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On-Demand Jenkins Slaves with Amazon EC2]]></title>
    <link href="http://artsy.github.io/blog/2012/07/10/on-demand-jenkins-slaves-with-amazon-ec2/"/>
    <updated>2012-07-10T13:30:00+01:00</updated>
    <id>http://artsy.github.io/blog/2012/07/10/on-demand-jenkins-slaves-with-amazon-ec2</id>
    <content type="html"><![CDATA[<p>The <a href="http://artsy.net">Artsy</a> team faithfully uses <a href="http://jenkins-ci.org">Jenkins</a> for continuous integration. <a href="http://artsy.github.com/blog/2012/05/27/using-jenkins-for-ruby-and-ruby-on-rails-teams/">As we've described before</a>, our Jenkins master and 8 slaves run on Linode. This arrangement has at least a few drawbacks:</p>

<ul>
<li>Our Linode servers are manually configured. They require frequent maintenance, and inconsistencies lead to surprising build failures.</li>
<li>The fixed set of slaves don't match the pattern of our build jobs: jobs get backed up during the day, but servers are mostly unused overnight and on weekends.</li>
</ul>


<p>The <a href="https://wiki.jenkins-ci.org/display/JENKINS/Amazon+EC2+Plugin">Amazon EC2 Plugin</a> allowed us to replace those slaves with a totally scripted environment. Now, slaves are spun up in the cloud whenever build jobs need them.</p>

<!-- more -->


<p>To set up the build slave's Amazon Machine Image (AMI), we started from an <a href="http://cloud-images.ubuntu.com/releases/oneiric/release/">official Ubuntu 11.10</a> (Oneiric Ocelot) AMI, ran initialization scripts to set up our build dependencies (MongoDB, Redis, ImageMagick, Firefox, RVM, NVM, etc.), packaged our modified instance into its own AMI, and then set up the EC2 Plugin to launch instances from this custom AMI.</p>

<p>Our AMI setup steps are captured entirely in a <a href="https://gist.github.com/3085368">GitHub gist</a>, but because our build requirements are specific to our applications and frameworks, most organizations will need to modify these scripts to their own use cases. Given that caveat, here's how we went from base Ubuntu AMI to custom build slave AMI:</p>

<ol>
<li>We <a href="https://console.aws.amazon.com/ec2/home?region=us-east-1#launchAmi=ami-4dad7424">launched</a> an Ubuntu 11.10 AMI <code>4dad7424</code> via the AWS console.</li>
<li>Once the instance was launched, we logged in with the SSH key we generated during setup.</li>
<li><p>We ran the following commands to configure the instance:</p>

<pre><code> curl -L https://raw.github.com/gist/3085368/_base-setup.sh | sudo bash -s
 sudo su -l jenkins
 curl -L https://raw.github.com/gist/3085368/_jenkins-user-setup.sh | bash -s
</code></pre></li>
<li><p>From the "Instances" tab of the AWS Console, we chose the now-configured instance, and from the "Instance Actions" dropdown, selected "Stop", followed by "Create Image (EBS AMI)".</p></li>
</ol>


<p>Next we installed the Amazon EC2 Plugin on our Jenkins master, and entered the following configuration arguments for the plugin. (Replace the AMI ID with your own, the result of Step 4 above.)</p>

<p>{% img /images/2012-07-10-on-demand-jenkins-slaves-with-amazon-ec2/ec2-plugin-config.png [Jenkins EC2 Plugin configuration] %}</p>

<p>New build slaves began spawning immediately in response to job demand! Our new "Computers" page on Jenkins looks like this:</p>

<p>{% img /images/2012-07-10-on-demand-jenkins-slaves-with-amazon-ec2/computer-list.png [Jenkins computer list] %}</p>

<p>We have the option of provisioning a new build slave via a single click, but so far, this hasn't been necessary, since slaves have automatically scaled up and down with demand. We average around 4-8 build slaves during the day, and 0-1 overnight and on weekends.</p>

<h2>Outcome and Next Steps</h2>

<p>This arrangement hasn't been in place for long, but we're excited about the benefits it's already delivered:</p>

<ul>
<li>Builds now take a predictable amount of time, since slaves automatically scale up to match demand.</li>
<li>Slaves offer a more consistent and easily maintained configuration, so there are fewer spurious failures.</li>
<li>Despite higher costs on EC2, we hope to spend about the same (or maybe even less) now that we'll need to operate only the master server during periods of inactivity (like nights and weekends).</li>
</ul>


<p>As proponents of <em>automating the hard stuff</em>, we get a real kick out of watching identical slaves spin up as builds trickle in each morning, then disappear as the queue quiets down in the evening. Still, there are a few improvements to be made:</p>

<ul>
<li>Our canonical slave's configuration should be scripted with <a href="http://www.opscode.com/chef/">Chef</a>.</li>
<li>Sharp-eyed readers will notice that our Jenkins master is still a Linode server. It might benefit from the same type of scripted configuration as the slaves.</li>
<li>Cooler still would be for the EC2 plugin to take advantage of Amazon's <a href="http://aws.amazon.com/ec2/spot-instances/">spot pricing</a>. Though not supported at the moment, it would allow us to spend a fraction as much (or spend the same amount, but on more powerful resources).</li>
</ul>

]]></content>
  </entry>
  
</feed>
